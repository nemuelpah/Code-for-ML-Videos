{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#HaarCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "HaarCascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
    "MyFaceNet = load_model('facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename):\n",
    "    image = cv2.imread(filename)\n",
    "    \n",
    "    #imagegray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    wajah = face_cascade.detectMultiScale(image,1.1,4)\n",
    "    \n",
    "    if len(wajah)>0:\n",
    "        x1, y1, width, height = wajah[0]         \n",
    "    else:\n",
    "        x1, y1, width, height = 1, 1, 10, 10\n",
    "        \n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    \n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)                  # konversi dari OpenCV ke PIL\n",
    "    image = asarray(image)\n",
    "    face = image[y1:y2, x1:x2]                         # extract the face\n",
    "    \n",
    "    image = Image.fromarray(face)                       # resize pixels to the model size\n",
    "    image = image.resize((160,160))\n",
    "    face_array = asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='train/'\n",
    "database = {}\n",
    "\n",
    "for filename in listdir(folder):\n",
    "\n",
    "    path = folder + filename\n",
    "    face = extract_face(path)\n",
    "    \n",
    "    face_pixels = face.astype('float32')\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face - mean) / std\n",
    "    \n",
    "    face = expand_dims(face, axis=0)\n",
    "    signature = model.predict(face)\n",
    "    \n",
    "    database[os.path.splitext(filename)[0]]=signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open(\"data.pkl\", \"wb\")\n",
    "pickle.dump(database, myfile)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
